## CatNLP

👋本项目聚焦于NLP技术，包括不限于命名实体识别，实体关系抽取，文本匹配，实体链接等技术

### 索引

### 命名实体识别（NER）

#### 想法

- FLAT + 词典类别，添加词典包括词典的类别

#### 分析工具

```
python analysis.py
```

以CLUE NER训练集为例：

长度统计

    count:  10748
    mean:   37.38
    std:    10.71
    min:    2
    50%:    41
    70%:    45
    90%:    49
    max:    50

文本长度直方图

![histogram](../image/ner/hist.png)

类别数目横条图

![hbar](../image/ner/hbar.png)

#### BiLSTM

```
python train.py --task=NER --train_config=data/config/ner/bilstm.yaml --log_config=data/config/ner/logging.yaml
```

#### BERT

```
python train.py --task=NER --train_config=data/config/ner/bert.yaml --log_config=data/config/ner/logging.yaml
```

#### ALBERT_TINY

```
python train.py --task=NER --train_config=data/config/ner/albert_tiny.yaml --log_config=data/config/ner/logging.yaml
```

### 实验

cmeee

epoch: 9
dev:
+-------+---------------------+--------------------+--------------------+-------+
| Label |          P          |         R          |         F1         | Equal |
+-------+---------------------+--------------------+--------------------+-------+
|  bod  |  0.6771217712177122 | 0.7240698985343855 | 0.6998093162625988 |  2569 |
|  dep  |  0.6461538461538462 | 0.711864406779661  | 0.6774193548387097 |   42  |
|  dis  |  0.7424749163879598 | 0.8196923076923077 | 0.779175197426148  |  2664 |
|  dru  |  0.759493670886076  | 0.8365019011406845 | 0.7961399276236429 |  660  |
|  equ  |  0.6733668341708543 | 0.7613636363636364 | 0.7146666666666668 |  134  |
|  ite  | 0.49236641221374045 | 0.5254582484725051 | 0.5083743842364532 |  258  |
|  mic  |  0.7451456310679612 | 0.7791878172588832 | 0.7617866004962778 |  307  |
|  pro  |  0.6520400307929176 | 0.6749003984063745 |  0.66327329678935  |  847  |
|  sym  |  0.5368674698795181 | 0.4812095032397408 | 0.5075170842824601 |  1114 |
| total |  0.6701754385964912 |  0.7000895984361   | 0.6848059915544578 |  8595 |
+-------+---------------------+--------------------+--------------------+-------+

test:

### 数据

- 半监督学习：动态伪标签（先使用训练数据得到一个不错的模型并结合投票策略对测试数据进行预测，得到的标签为伪标签，将其加入到训练数据中一同训练，计算loss是对是否是伪标签进行加权）
- 数据去噪：使用Roberta-CRF-FGM模型对训练集进行10折交叉验证对标注实体进行过滤，具体过滤规则为：10折训练得到10份预测结果，如果在10份预测结果中都有则保留，如果一个也没有但是原始训练集中标注了则去除。
- 实体补全：匹配相同的文本，补上标注

### 训练

- 差分学习率
- 对抗训练：FGM,PGD（提升模型泛化性能）

### 模型

- 滑动参数平均：加权平均最后几个epoch模型的权重


### 融合

- 对不同模型的Bert输出层概率、CRF的转移概率进行权重平均
- 在每一折中，保留 f1值最高的模型，在输出的单元标签中，进行服从多数投票，如10折的预测结果，其中7折预测为B-eff、其它三折预测为O，则取B-eff
- 在每一折中，保留 recall最高的模型，在输出的实体标签中，进行阈值保留，如10折的预测结果，其中7折预测出“脾虚”这一实体，另外3折没有预测出来，假如阈值取≥7，则保留，否则丢弃

### 规则

- 舍弃过长的实体，舍弃带特殊字符的实体，融合的实体进行分割


### 训练方式

替换部分实体为[MASK]，强调上下文特征